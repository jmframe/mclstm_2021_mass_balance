{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XArray version:  0.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl \n",
    "import xarray as xr\n",
    "import copy\n",
    "import os\n",
    "import sys \n",
    "import metrics\n",
    "from sklearn.metrics import mutual_info_score\n",
    "print(\"XArray version: \", xr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# LOAD IN THE DATA\n",
    "##########################################################################################################\n",
    "with open('./model_output_for_analysis/nwm_chrt_v2_1d_local.p', 'rb') as fb: \n",
    "    nwm_results = pkl.load(fb)\n",
    "\n",
    "lstm_results_time_split1={}\n",
    "mclstm_results_time_split1={}\n",
    "sacsma_results_time_split1={}\n",
    "lstm_results_time_split2={}\n",
    "mclstm_results_time_split2={}\n",
    "sacsma_results_time_split2={}\n",
    "\n",
    "for forcing_type in ['nldas', 'daymet']:\n",
    "    \n",
    "    with open('./model_output_for_analysis/lstm_time_split1_{}_ens.p'.format(forcing_type), 'rb') as fb: \n",
    "        lstm_results_time_split1[forcing_type] = pkl.load(fb)\n",
    "    with open('./model_output_for_analysis/mclstm_time_split1_{}_ens.p'.format(forcing_type), 'rb') as fb: \n",
    "        mclstm_results_time_split1[forcing_type] = pkl.load(fb)\n",
    "    with open('./model_output_for_analysis/sacsma_time_split1_{}_ens.p'.format(forcing_type), 'rb') as fb: \n",
    "        sacsma_results_time_split1[forcing_type] = pkl.load(fb)\n",
    "\n",
    "    with open('./model_output_for_analysis/lstm_time_split2_{}.p'.format(forcing_type), 'rb') as fb: \n",
    "        lstm_results_time_split2[forcing_type] = pkl.load(fb)\n",
    "    with open('./model_output_for_analysis/mclstm_time_split2_{}.p'.format(forcing_type), 'rb') as fb: \n",
    "        mclstm_results_time_split2[forcing_type] = pkl.load(fb)\n",
    "    with open('./model_output_for_analysis/sacsma_time_split2_{}.p'.format(forcing_type), 'rb') as fb: \n",
    "        sacsma_results_time_split2[forcing_type] = pkl.load(fb)\n",
    "\n",
    "train_split_type_model_set = {'time_split1':{'nwm':nwm_results, \n",
    "                                           'lstm':lstm_results_time_split1,\n",
    "                                            'mc':mclstm_results_time_split1,\n",
    "                                            'sac':sacsma_results_time_split1},\n",
    "                              'time_split2':{'nwm':nwm_results,\n",
    "                                           'lstm':lstm_results_time_split2,\n",
    "                                            'mc':mclstm_results_time_split2,\n",
    "                                            'sac':sacsma_results_time_split2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# USE A CONVERSION BETWEEN MODELS AND DATA\n",
    "##########################################################################################################\n",
    "# Convert flow to   CFS mm -> ft     km^2 -> ft^2    hr->s\n",
    "conversion_factor = 0.00328084 * 10763910.41671 / 3600 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Get all the CAMELS attributes.  \n",
    "##########################################################################################################\n",
    "\n",
    "# Camels attributes with RI information\n",
    "dataName = '../data/camels_attributes.csv'\n",
    "# load the data with pandas\n",
    "pd_attributes = pd.read_csv(dataName, sep=',', index_col='gauge_id')\n",
    "\n",
    "# Add the basin ID as a 8 element string with a leading zero if neccessary\n",
    "basin_id_str = []\n",
    "for a in pd_attributes.index.values:\n",
    "    basin_id_str.append(str(a).zfill(8))\n",
    "pd_attributes['basin_id_str'] = basin_id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# Loop through all the SACSMA runs and check that the results are good. \n",
    "# Get a list of basins that has good calibration results.\n",
    "##########################################################################################################\n",
    "basin_list_all_camels = list(pd_attributes['basin_id_str'].values)\n",
    "basin_list_sacsma_good = {ts:copy.deepcopy(basin_list_all_camels) for ts in ['time_split1', 'time_split2']}\n",
    "\n",
    "for ib, basin_0str in enumerate(basin_list_all_camels): \n",
    "    remove_basin_id_from_list = False\n",
    "    for train_split_type in ['time_split1', 'time_split2']:\n",
    "        for forcing_type in ['nldas', 'daymet']:\n",
    "\n",
    "            if basin_0str not in list(train_split_type_model_set[train_split_type]['sac'][forcing_type].columns):\n",
    "                remove_basin_id_from_list = True\n",
    "            elif train_split_type_model_set[train_split_type]['sac'][forcing_type][basin_0str].sum() <=0:\n",
    "                remove_basin_id_from_list = True\n",
    "\n",
    "            if train_split_type == 'time_split2' and forcing_type == 'nldas':\n",
    "                if basin_0str not in list(train_split_type_model_set[train_split_type]['nwm'].keys()):\n",
    "                    remove_basin_id_from_list = True\n",
    "\n",
    "    if remove_basin_id_from_list:\n",
    "        basin_list_sacsma_good[train_split_type].remove(basin_0str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "#-------------------------------------------------------------------------------------------------\n",
    "# Solve this problem. I think it is the xarray structures...\n",
    "# isibleDeprecationWarning: Creating an ndarray from ragged nested sequences \n",
    "# (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. \n",
    "# If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
    "##########################################################################################################\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# REVERT TO THESE AS THE FLOWS\n",
    "##########################################################################################################\n",
    "flows = ['lstm', 'mc', 'sac', 'obs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specifications(tsplt, forcing_type):\n",
    "    \"\"\"\n",
    "    This function is designed to return specific details of the simulation period\n",
    "    Inputs:\n",
    "        tsplit (str): Either time_split2 or time_split1\n",
    "        forcing_type (str): Either nldas or daymet\n",
    "    Returns\n",
    "        start_date (pd.Timestamp): The date the simulation period started\n",
    "        end_date (pd.Timestamp): The date the simulation period ended\n",
    "        labelz (dictionary): A mapping between short model name and long model name\n",
    "        models (list): the short model names\n",
    "        flows (list): the short model names plus \"obs\" for observed flow\n",
    "        basin_list (list): the list of basins that meet the criteria for analysis\n",
    "        tsplit (str): Either time_split2 or time_split1\n",
    "    \"\"\"\n",
    "    if tsplt == 'time_split2' and forcing_type == 'nldas':\n",
    "        start_date = pd.Timestamp('1996-10-01')\n",
    "        end_date = pd.Timestamp('2014-01-01')\n",
    "        labelz={'nwm':'NWM*', 'lstm':'LSTM', 'mc':'MC-LSTM','sac':'SAC-SMA', 'obs':'Observed'}\n",
    "        models = ['nwm', 'lstm', 'mc', 'sac']\n",
    "        flows = ['nwm', 'lstm', 'mc', 'sac', 'obs']\n",
    "        basin_list = list(lstm_results_time_split2[forcing_type].keys())[:-1]\n",
    "    elif tsplt == 'time_split2':\n",
    "        start_date = pd.Timestamp('1996-10-01')\n",
    "        end_date = pd.Timestamp('2014-01-01')\n",
    "        labelz={'lstm':'LSTM', 'mc':'MC-LSTM','sac':'SAC-SMA', 'obs':'Observed'}\n",
    "        models = ['lstm', 'mc', 'sac']\n",
    "        flows = ['lstm', 'mc', 'sac', 'obs']\n",
    "        basin_list = list(lstm_results_time_split2[forcing_type].keys())[:-1]\n",
    "    else:\n",
    "        start_date = pd.Timestamp('1989-10-01')\n",
    "        end_date = pd.Timestamp('1999-09-30')\n",
    "        labelz={'lstm':'LSTM', 'mc':'MC-LSTM','sac':'SAC-SMA', 'obs':'Observed'}\n",
    "        models = ['lstm', 'mc', 'sac']\n",
    "        flows = ['lstm', 'mc', 'sac', 'obs']\n",
    "        basin_list = list(lstm_results_time_split1[forcing_type].keys())[:-1]\n",
    "\n",
    "    spex = {\"start_date\":start_date,\n",
    "            \"end_date\":end_date,\n",
    "            \"labelz\":labelz,\n",
    "            \"models\":models,\n",
    "            \"flows\":flows, \n",
    "            \"basin_list\":basin_list,\n",
    "            \"tsplt\":tsplt}\n",
    "    return spex #(start_date, end_date, labelz, models, flows, basin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_forcing_and_identify_events(tsplt, basin_0str, forcing_dir, file_name_map, forcing_type):\n",
    "    \"\"\"\n",
    "    This function loads in the forcing, and also identifies the indices of precipitation \"events\"\n",
    "    Events are arbitrarily defined as any time the precipitation is greater than the median (non zero) precip\n",
    "    \n",
    "    Inputs:\n",
    "        tsplit (str): Either time_split2 or time_split1\n",
    "        basin_0str (str): The basin ID as a string with a leading zero\n",
    "        forcing_dir (str): The directory where to find the forcing file\n",
    "        file_name_map (dictionary): \n",
    "        forcing_type (str): either nldas or daymet\n",
    "    Return:\n",
    "        forcing (pd.DataFrame): The forcing data for a particular basin\n",
    "        precip_events (list): Indices of official precipitation \"events\"\n",
    "    \"\"\"\n",
    "    basin_int = int(basin_0str)\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # FORCING\n",
    "    forcing = pd.read_csv(f'{forcing_dir}{basin_0str}_lump_{file_name_map[forcing_type]}_forcing_leap.txt',\n",
    "                          delim_whitespace=True, header=3)\n",
    "    if tsplt == 'time_split1':\n",
    "        forcing = forcing.iloc[3560:7214]\n",
    "    if tsplt == 'time_split2':\n",
    "        forcing = forcing.iloc[6118:]\n",
    "    forcing.index=pd.to_datetime((forcing.Year*10000+forcing.Mnth*100+forcing.Day).apply(str),format='%Y%m%d')\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    precip_threshold_50 = 0\n",
    "    any_precip = forcing[\"PRCP(mm/day)\"][forcing[\"PRCP(mm/day)\"]>0].values\n",
    "    any_precip.sort()\n",
    "    onethrough = np.array([i for i in range(any_precip.shape[0])])/any_precip.shape[0]\n",
    "    for i in range(any_precip.shape[0]):\n",
    "        if onethrough[i] > .5:\n",
    "            precip_threshold_50 = any_precip[i]\n",
    "            break\n",
    "            \n",
    "    precip_events=[]\n",
    "    # Get indices of precipitation events that have no such event two days prior, nor three days after\n",
    "    for i, precip in enumerate(forcing[\"PRCP(mm/day)\"]):\n",
    "        if i < 3 or i > (forcing[\"PRCP(mm/day)\"].shape[0]-3):\n",
    "            continue\n",
    "        if precip > precip_threshold_50:\n",
    "            if np.sum(forcing[\"PRCP(mm/day)\"][i-3:i]) < precip_threshold_50:\n",
    "                if np.sum(forcing[\"PRCP(mm/day)\"][i+1:i+5]) < precip_threshold_50:\n",
    "                    precip_events.append(i)\n",
    "                \n",
    "    print(\"Number of precipitation events\", len(precip_events))\n",
    "    \n",
    "    return forcing, precip_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mass_balance_over_events(basin_0str, spex, forcing, precip_events):\n",
    "    \n",
    "    basin_int = int(basin_0str)\n",
    "    start_date = spex[\"start_date\"]\n",
    "    end_date = spex[\"end_date\"]\n",
    "    tsplt = spex[\"tsplt\"]\n",
    "    models = spex['models']\n",
    "    flows = spex['flows']\n",
    "    \n",
    "    mass_balance_over_events = pd.DataFrame(columns=[\"event\",\n",
    "                                                     \"event_date\",\n",
    "                                                     \"total_precip\", \n",
    "                                                     \"total_obs\", \n",
    "                                                     \"total_lstm\",\n",
    "                                                     \"total_mc\",\n",
    "                                                     \"total_sac\",\n",
    "                                                     \"runoff_ratio\",\n",
    "                                                     \"AME_lstm\",\n",
    "                                                     \"PME_lstm\",\n",
    "                                                     \"NME_lstm\",\n",
    "                                                     \"AME_mc\",\n",
    "                                                     \"PME_mc\",\n",
    "                                                     \"NME_mc\",\n",
    "                                                     \"AME_sac\",\n",
    "                                                     \"PME_sac\",\n",
    "                                                     \"NME_sac\"])\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # Reset the total mass to zero for this basin    \n",
    "    cumulative_mass = {event:{flow:[0] for flow in flows} for event in precip_events}\n",
    "    for event in precip_events:\n",
    "        cumulative_mass[event]['precip'] = [0]\n",
    "    total_mass[forcing_type][tsplt][basin_0str] = {event:{flow:0 for flow in flows} for event in precip_events}\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # We need the basin area to convert to CFS, to interpolate the RI from LPIII\n",
    "    basin_area = pd_attributes.loc[basin_int, 'area_geospa_fabric']\n",
    "    basin_str = str(basin_int).zfill(8)\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # Make dictionary with all the flows\n",
    "    flow_mm = {}\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    if tsplt == 'time_split2' and forcing_type == 'nldas':\n",
    "        # Get the NWM data for this basin in an xarray dataset.\n",
    "        xr_nwm = xr.DataArray(nwm_results[basin_0str]['streamflow'].values,\n",
    "                 coords=[nwm_results[basin_0str]['streamflow'].index],\n",
    "                 dims=['datetime'])\n",
    "        # convert from CFS to mm/day\n",
    "        # fm3/s * 3600 sec/hour * 24 hour/day / (m2 * mm/m)\n",
    "        flow_mm['nwm'] = xr_nwm.loc[start_date:end_date]*3600*24/(basin_area*1000)\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # Standard LSTM \n",
    "    if tsplt == 'time_split1':\n",
    "        xrr = lstm_results_time_split1[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_sim'].loc[start_date:end_date]\n",
    "        flow_mm['lstm'] = pd.DataFrame(data=xrr.values,index=xrr.datetime.values)\n",
    "    if tsplt == 'time_split2':\n",
    "        xrr = lstm_results_time_split2[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_sim'].loc[start_date:end_date]\n",
    "        flow_mm['lstm'] = pd.DataFrame(data=xrr.values,index=xrr.date.values)\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # Mass-conserving LSTM data trained on all years\n",
    "    if tsplt == 'time_split1':\n",
    "        xrr = mclstm_results_time_split1[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_sim'].loc[start_date:end_date]\n",
    "        flow_mm['mc'] = pd.DataFrame(data=xrr.values,index=xrr.datetime.values)\n",
    "    if tsplt == 'time_split2':\n",
    "        xrr = mclstm_results_time_split2[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_sim'].loc[start_date:end_date]\n",
    "        flow_mm['mc'] = pd.DataFrame(data=xrr.values,index=xrr.date.values)\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # SACSMA Mean\n",
    "    if tsplt == 'time_split1':\n",
    "        df = sacsma_results_time_split1[forcing_type][basin_0str].loc[start_date:end_date]\n",
    "    if tsplt == 'time_split2':\n",
    "        df = sacsma_results_time_split2[forcing_type][basin_0str].loc[start_date:end_date]\n",
    "    flow_mm['sac'] = df\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # OBSERVATIONS\n",
    "    if tsplt == 'time_split1':\n",
    "        xrr = mclstm_results_time_split1[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_obs'].loc[start_date:end_date]\n",
    "        flow_mm['obs'] = pd.DataFrame(data=xrr.values,index=xrr.datetime.values)\n",
    "    if tsplt == 'time_split2':\n",
    "        xrr = mclstm_results_time_split2[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_obs'].loc[start_date:end_date]\n",
    "        flow_mm['obs'] = pd.DataFrame(data=xrr.values,index=xrr.date.values)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    # Make sure we are in a time period that all the flow members have values\n",
    "    # If there is missin observations than we can't compare the mass of the observed with simulaitons\n",
    "    skip_basin_because_missing_obs = False\n",
    "    if tsplt == 'time_split1':\n",
    "        obs_temp = mclstm_results_time_split1[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_obs'].datetime\n",
    "    if tsplt == 'time_split2':\n",
    "        obs_temp = mclstm_results_time_split2[forcing_type][basin_0str]['1D']['xr']['QObs(mm/d)_obs'].date\n",
    "\n",
    "#     for event in precip_events:\n",
    "        \n",
    "#         for d in obs_temp[event-3:event+5]:\n",
    "            \n",
    "#             imass=1\n",
    "            \n",
    "#             if d.values < start_date:\n",
    "#                 continue\n",
    "#             if d.values > end_date:\n",
    "#                 break\n",
    "#             if np.isnan(flow_mm['obs'].loc[d.values].values[0]):\n",
    "#                 skip_basin_because_missing_obs = True\n",
    "#                 break\n",
    "#             else:\n",
    "#                 #-----------------------------------------------------------------------------------------\n",
    "#                 # Keep track of the cumulative mass and add it to the list\n",
    "#                 cumulative_mass[event]['precip'].append(forcing[precip_column_map[forcing_type]].loc[d.values] + \\\n",
    "#                                                  cumulative_mass[event]['precip'][imass-1])\n",
    "\n",
    "#                 cumulative_mass[event]['obs'].append(flow_mm['obs'].loc[d.values].values[0] + \\\n",
    "#                                               cumulative_mass[event]['obs'][imass-1])\n",
    "\n",
    "#                 if tsplt == 'time_split2' and forcing_type == 'nldas':\n",
    "#                     cumulative_mass[event]['nwm'].append(flow_mm['nwm'].loc[d.values].values + \\\n",
    "#                                               cumulative_mass[event]['obs'][imass-1])\n",
    "\n",
    "#                 if tsplt == 'time_split2' and forcing_type == 'nldas':\n",
    "#                     cumulative_mass[event]['nwm'].append(flow_mm['nwm'].loc[d.values].values + \\\n",
    "#                                                   cumulative_mass[event]['nwm'][imass-1])\n",
    "\n",
    "#                 cumulative_mass[event]['lstm'].append(flow_mm['lstm'].loc[d.values].values[0] + \\\n",
    "#                                                cumulative_mass[event]['lstm'][imass-1])\n",
    "\n",
    "#                 cumulative_mass[event]['mc'].append(flow_mm['mc'].loc[d.values].values[0] + \\\n",
    "#                                              cumulative_mass[event]['mc'][imass-1])\n",
    "\n",
    "#                 cumulative_mass[event]['sac'].append(flow_mm['sac'].loc[d.values] + \\\n",
    "#                                               cumulative_mass[event]['sac'][imass-1])\n",
    "#                 imass+=1\n",
    "#                 #----------------------------------------------------------------------------------------\n",
    "                \n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    #################    DO MASS PER EVENT\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    mass_basin_list[tsplt].append(basin_0str)\n",
    "\n",
    "    for event in precip_events:\n",
    "        \n",
    "        mass_balance_over_events.loc[event,'event'] = event\n",
    "        \n",
    "        sevd = event-3# StartEventDate\n",
    "        eevd = event+5# EndEventDate\n",
    "        \n",
    "        for flow in flows:\n",
    "            \n",
    "            total_mass[forcing_type][tsplt][basin_0str][event][flow] = np.nansum(flow_mm[flow].iloc[sevd:eevd])\n",
    "                        \n",
    "        ts = pd.to_datetime(str(forcing[precip_column_map[forcing_type]].index.values[event])) \n",
    "        d = ts.strftime('%Y.%m.%d')\n",
    "        mass_balance_over_events.loc[event,'event_date'] = d\n",
    "        mass_balance_over_events.loc[event,'total_precip'] = \\\n",
    "             np.sum(forcing[precip_column_map[forcing_type]].values[sevd:eevd])\n",
    "        mass_balance_over_events.loc[event,'total_obs'] = \\\n",
    "            total_mass[forcing_type][tsplt][basin_0str][event]['obs']\n",
    "        mass_balance_over_events.loc[event,'total_lstm'] = \\\n",
    "            total_mass[forcing_type][tsplt][basin_0str][event]['lstm']\n",
    "        mass_balance_over_events.loc[event,'total_mc'] = \\\n",
    "            total_mass[forcing_type][tsplt][basin_0str][event]['mc']\n",
    "        mass_balance_over_events.loc[event,'total_sac'] = \\\n",
    "            total_mass[forcing_type][tsplt][basin_0str][event]['sac']\n",
    "        mass_balance_over_events.loc[event,'runoff_ratio'] = \\\n",
    "            mass_balance_over_events.loc[event,'total_obs'] / \\\n",
    "            mass_balance_over_events.loc[event,'total_precip']\n",
    "\n",
    "\n",
    "        for model in models:\n",
    "            \n",
    "            _obs = total_mass[forcing_type][tsplt][basin_0str][event]['obs']\n",
    "            _sim = total_mass[forcing_type][tsplt][basin_0str][event][model]\n",
    "            \n",
    "            mass_balance_over_events.loc[event,f'AME_{model}'] = np.abs(_sim - _obs) / _obs\n",
    "            if (_sim - _obs) > 0:\n",
    "                mass_balance_over_events.loc[event,f'PME_{model}'] = (_sim - _obs) / _obs\n",
    "                mass_balance_over_events.loc[event,f'NME_{model}'] = 0\n",
    "            else:\n",
    "                mass_balance_over_events.loc[event,f'NME_{model}'] = (_sim - _obs) / _obs\n",
    "                mass_balance_over_events.loc[event,f'PME_{model}'] = 0\n",
    "\n",
    "    return mass_balance_over_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsplt time_split1\n",
      "forcing_type  nldas\n",
      "01022500\n",
      "Number of precipitation events 62\n",
      "LSTM absolute mass error 0.34070513325352825\n",
      "MC-LSTM absolute mass error 0.3318684793287708\n",
      "SacSMA absolute mass error 0.41735557471304946\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################################\n",
    "# IDENTIFY EVENTS WITH PRECIP OVER 10mm\n",
    "# THEN DO THE MASS BALANCE CALC OVER SOME WINDOW\n",
    "##########################################################################################################\n",
    "forcing_products = ['nldas','daymet']\n",
    "\n",
    "file_name_map = {'nldas':'nldas', 'daymet':'cida'}\n",
    "precip_column_map = {'nldas':'PRCP(mm/day)', 'daymet':'prcp(mm/day)'}\n",
    "\n",
    "# total_mass_error = {event:{forcing_type:{time_split:{'absolute':{flow:[] for flow in flows},\n",
    "#       'positive':{flow:[] for flow in flows},\n",
    "#       'negative':{flow:[] for flow in flows}} for time_split in ['time_split1', 'time_split2']} for \\\n",
    "#        forcing_type in forcing_products} for event in precip_events}\n",
    "\n",
    "# for err_type in ['absolute','positive', 'negative']:\n",
    "#     total_mass_error['nldas']['time_split2'][err_type]['nwm']=[]\n",
    "\n",
    "# cumulative_mass_all = {forcing_type:{time_split:{} for time_split in ['time_split1', 'time_split2']} for \\\n",
    "#                        forcing_type in forcing_products}\n",
    "\n",
    "total_mass = {forcing_type:{time_split:{} for time_split in ['time_split1', 'time_split2']} for \\\n",
    "                       forcing_type in forcing_products}\n",
    "\n",
    "mass_basin_list={}\n",
    "\n",
    "for tsplt in ['time_split1', 'time_split2']:\n",
    "    print('tsplt', tsplt)\n",
    "    for forcing_type in forcing_products:\n",
    "\n",
    "        print('forcing_type ',forcing_type)\n",
    "\n",
    "        mass_basin_list[tsplt] = []\n",
    "        forcing_dir = '/home/NearingLab/data/camels_data/basin_dataset_public_v1p2'+\\\n",
    "            '/basin_mean_forcing/{}_all_basins_in_one_directory/'.format(forcing_type)\n",
    "\n",
    "        spex = get_specifications(tsplt, forcing_type)\n",
    "\n",
    "        first_basin = True\n",
    "\n",
    "        for basin_0str in spex[\"basin_list\"]:\n",
    "            \n",
    "            print(basin_0str)\n",
    "            \n",
    "            forcing, precip_events = load_forcing_and_identify_events(tsplt, \n",
    "                                                                      basin_0str, \n",
    "                                                                      forcing_dir, \n",
    "                                                                      file_name_map, \n",
    "                                                                      forcing_type)\n",
    "            \n",
    "            mass_balance_over_events = calculate_mass_balance_over_events(basin_0str, \n",
    "                                                                          spex, \n",
    "                                                                          forcing, \n",
    "                                                                          precip_events)\n",
    "            \n",
    "            print(\"LSTM absolute mass error\", np.mean(mass_balance_over_events.loc[:,'AME_lstm']))\n",
    "            print(\"MC-LSTM absolute mass error\", np.mean(mass_balance_over_events.loc[:,'AME_mc']))\n",
    "            print(\"SacSMA absolute mass error\", np.mean(mass_balance_over_events.loc[:,'AME_sac']))\n",
    "            \n",
    "            break\n",
    "\n",
    "        break\n",
    "        \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>event_date</th>\n",
       "      <th>total_precip</th>\n",
       "      <th>total_obs</th>\n",
       "      <th>total_lstm</th>\n",
       "      <th>total_mc</th>\n",
       "      <th>total_sac</th>\n",
       "      <th>runoff_ratio</th>\n",
       "      <th>AME_lstm</th>\n",
       "      <th>PME_lstm</th>\n",
       "      <th>NME_lstm</th>\n",
       "      <th>AME_mc</th>\n",
       "      <th>PME_mc</th>\n",
       "      <th>NME_mc</th>\n",
       "      <th>AME_sac</th>\n",
       "      <th>PME_sac</th>\n",
       "      <th>NME_sac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1989.10.11</td>\n",
       "      <td>23.52</td>\n",
       "      <td>6.47784</td>\n",
       "      <td>11.594068</td>\n",
       "      <td>10.486248</td>\n",
       "      <td>11.78696</td>\n",
       "      <td>0.275418</td>\n",
       "      <td>0.789804</td>\n",
       "      <td>0.789804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618788</td>\n",
       "      <td>0.618788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819582</td>\n",
       "      <td>0.819582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>1989.12.07</td>\n",
       "      <td>10.17</td>\n",
       "      <td>7.835024</td>\n",
       "      <td>12.579723</td>\n",
       "      <td>13.387175</td>\n",
       "      <td>10.741683</td>\n",
       "      <td>0.770405</td>\n",
       "      <td>0.605576</td>\n",
       "      <td>0.605576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370983</td>\n",
       "      <td>0.370983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>1989.12.16</td>\n",
       "      <td>15.24</td>\n",
       "      <td>6.094832</td>\n",
       "      <td>8.719742</td>\n",
       "      <td>8.201403</td>\n",
       "      <td>8.388856</td>\n",
       "      <td>0.399923</td>\n",
       "      <td>0.430678</td>\n",
       "      <td>0.430678</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345632</td>\n",
       "      <td>0.345632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376388</td>\n",
       "      <td>0.376388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>1990.01.05</td>\n",
       "      <td>2.27</td>\n",
       "      <td>9.833329</td>\n",
       "      <td>12.827887</td>\n",
       "      <td>11.774343</td>\n",
       "      <td>10.516388</td>\n",
       "      <td>4.331863</td>\n",
       "      <td>0.304531</td>\n",
       "      <td>0.304531</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197391</td>\n",
       "      <td>0.197391</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>1990.02.04</td>\n",
       "      <td>10.52</td>\n",
       "      <td>15.853225</td>\n",
       "      <td>21.448011</td>\n",
       "      <td>18.991274</td>\n",
       "      <td>11.648147</td>\n",
       "      <td>1.506961</td>\n",
       "      <td>0.352912</td>\n",
       "      <td>0.352912</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197944</td>\n",
       "      <td>0.197944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265251</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.265251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>3413</td>\n",
       "      <td>1999.02.03</td>\n",
       "      <td>37.05</td>\n",
       "      <td>44.895271</td>\n",
       "      <td>34.298752</td>\n",
       "      <td>30.877831</td>\n",
       "      <td>33.15684</td>\n",
       "      <td>1.211748</td>\n",
       "      <td>0.236028</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.236028</td>\n",
       "      <td>0.312225</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.312225</td>\n",
       "      <td>0.261463</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.261463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>3423</td>\n",
       "      <td>1999.02.13</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.438534</td>\n",
       "      <td>19.184235</td>\n",
       "      <td>14.863183</td>\n",
       "      <td>20.114732</td>\n",
       "      <td>2.75202</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193906</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.193906</td>\n",
       "      <td>0.090907</td>\n",
       "      <td>0.090907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>3483</td>\n",
       "      <td>1999.04.14</td>\n",
       "      <td>2.87</td>\n",
       "      <td>17.564274</td>\n",
       "      <td>22.607628</td>\n",
       "      <td>21.092661</td>\n",
       "      <td>9.89182</td>\n",
       "      <td>6.119956</td>\n",
       "      <td>0.287137</td>\n",
       "      <td>0.287137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200884</td>\n",
       "      <td>0.200884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436822</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.436822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>3495</td>\n",
       "      <td>1999.04.26</td>\n",
       "      <td>2.67</td>\n",
       "      <td>12.755852</td>\n",
       "      <td>11.514612</td>\n",
       "      <td>11.169155</td>\n",
       "      <td>7.183783</td>\n",
       "      <td>4.777473</td>\n",
       "      <td>0.097307</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097307</td>\n",
       "      <td>0.12439</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.12439</td>\n",
       "      <td>0.436824</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.436824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613</th>\n",
       "      <td>3613</td>\n",
       "      <td>1999.08.22</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.219799</td>\n",
       "      <td>1.613076</td>\n",
       "      <td>1.549304</td>\n",
       "      <td>1.531448</td>\n",
       "      <td>0.248432</td>\n",
       "      <td>0.322411</td>\n",
       "      <td>0.322411</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0.27013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255492</td>\n",
       "      <td>0.255492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     event  event_date total_precip  total_obs total_lstm   total_mc  \\\n",
       "11      11  1989.10.11        23.52    6.47784  11.594068  10.486248   \n",
       "68      68  1989.12.07        10.17   7.835024  12.579723  13.387175   \n",
       "77      77  1989.12.16        15.24   6.094832   8.719742   8.201403   \n",
       "97      97  1990.01.05         2.27   9.833329  12.827887  11.774343   \n",
       "127    127  1990.02.04        10.52  15.853225  21.448011  18.991274   \n",
       "...    ...         ...          ...        ...        ...        ...   \n",
       "3413  3413  1999.02.03        37.05  44.895271  34.298752  30.877831   \n",
       "3423  3423  1999.02.13          6.7  18.438534  19.184235  14.863183   \n",
       "3483  3483  1999.04.14         2.87  17.564274  22.607628  21.092661   \n",
       "3495  3495  1999.04.26         2.67  12.755852  11.514612  11.169155   \n",
       "3613  3613  1999.08.22         4.91   1.219799   1.613076   1.549304   \n",
       "\n",
       "      total_sac runoff_ratio  AME_lstm  PME_lstm  NME_lstm    AME_mc  \\\n",
       "11     11.78696     0.275418  0.789804  0.789804         0  0.618788   \n",
       "68    10.741683     0.770405  0.605576  0.605576         0  0.708632   \n",
       "77     8.388856     0.399923  0.430678  0.430678         0  0.345632   \n",
       "97    10.516388     4.331863  0.304531  0.304531         0  0.197391   \n",
       "127   11.648147     1.506961  0.352912  0.352912         0  0.197944   \n",
       "...         ...          ...       ...       ...       ...       ...   \n",
       "3413   33.15684     1.211748  0.236028         0 -0.236028  0.312225   \n",
       "3423  20.114732      2.75202  0.040443  0.040443         0  0.193906   \n",
       "3483    9.89182     6.119956  0.287137  0.287137         0  0.200884   \n",
       "3495   7.183783     4.777473  0.097307         0 -0.097307   0.12439   \n",
       "3613   1.531448     0.248432  0.322411  0.322411         0   0.27013   \n",
       "\n",
       "        PME_mc    NME_mc   AME_sac   PME_sac   NME_sac  \n",
       "11    0.618788         0  0.819582  0.819582         0  \n",
       "68    0.708632         0  0.370983  0.370983         0  \n",
       "77    0.345632         0  0.376388  0.376388         0  \n",
       "97    0.197391         0  0.069464  0.069464         0  \n",
       "127   0.197944         0  0.265251         0 -0.265251  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "3413         0 -0.312225  0.261463         0 -0.261463  \n",
       "3423         0 -0.193906  0.090907  0.090907         0  \n",
       "3483  0.200884         0  0.436822         0 -0.436822  \n",
       "3495         0  -0.12439  0.436824         0 -0.436824  \n",
       "3613   0.27013         0  0.255492  0.255492         0  \n",
       "\n",
       "[62 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_balance_over_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
